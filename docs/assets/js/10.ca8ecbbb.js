(window.webpackJsonp=window.webpackJsonp||[]).push([[10],{335:function(t,s,a){"use strict";a.r(s);var e=a(4),n=Object(e.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h3",{attrs:{id:"hive最佳实践"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hive最佳实践"}},[t._v("#")]),t._v(" Hive最佳实践")]),t._v(" "),s("h4",{attrs:{id:"数据分层-京东"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#数据分层-京东"}},[t._v("#")]),t._v(" 数据分层(京东)")]),t._v(" "),s("p",[s("img",{attrs:{src:"/img/%E6%95%B0%E4%BB%93-%E6%95%B0%E6%8D%AE%E5%88%86%E5%B1%82.png",alt:"数仓-数据分层"}})]),t._v(" "),s("p",[t._v("BDM—数据缓存层，同ODS，主要是为了命名统一，存放大表的增量数据，按照自然时间分区，")]),t._v(" "),s("p",[t._v("FDM—数据基础层，存放全量数据，大表按照创建时间分区，小表非分区")]),t._v(" "),s("p",[t._v("GDM—数据汇总层，数据的预关联、预汇总及预加工；依赖对应用的共性提炼")]),t._v(" "),s("p",[t._v("ADM—数据应用层，主要是为了命名统一，面向应用，按需定制，即最终结果表存放的数据库")]),t._v(" "),s("p",[t._v("DIM—固定数据层，比如国家代码和国家名、地理位置、中文名、国旗图片等")]),t._v(" "),s("p",[t._v("TMP—存放临时数据表")]),t._v(" "),s("p",[t._v("做好数据分层，构建数据集市，能合理使用计算资源，避免重复计算")]),t._v(" "),s("h4",{attrs:{id:"数据分层-常规"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#数据分层-常规"}},[t._v("#")]),t._v(" 数据分层(常规)")]),t._v(" "),s("p",[t._v("DIM - 固定数据层，比如国家代码和国家名、地理位置、中文名、国旗图片等，还包括客户表，产品表的基础字段")]),t._v(" "),s("p",[t._v("ODM - 数据缓存层，主要是为了命名统一，存放大表的增量数据，按照自然时间分区")]),t._v(" "),s("p",[t._v("DWD - 数据基础层，存放全量数据，大表按照创建时间分区，小表非分区")]),t._v(" "),s("p",[t._v("FACT-- 事实数据层，一般为事实事件触发")]),t._v(" "),s("p",[t._v("DWS - 轻度聚合层，像客户历史下单数这样的聚合属性")]),t._v(" "),s("p",[t._v("ADS - 数据应用层，主要是为了命名统一，面向应用，按需定制，即最终结果表存放的数据库")]),t._v(" "),s("h4",{attrs:{id:"数据分区"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#数据分区"}},[t._v("#")]),t._v(" 数据分区")]),t._v(" "),s("p",[t._v("除常量数据库表外，所有数据表都应该分区，在作业流中，周期性的获取或生成数据，一般按时间分区，每个分区内存放全量或增量数据")]),t._v(" "),s("p",[t._v("按全量存放，每个分区都保存全量数据的快照，数据即取即用，但后面每个分区的数据递增；按增量存放，使用数据需要加一层处理，但分区的数据均匀且数据量小，推荐增量存放")]),t._v(" "),s("h4",{attrs:{id:"数据格式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#数据格式"}},[t._v("#")]),t._v(" 数据格式")]),t._v(" "),s("h5",{attrs:{id:"储存格式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#储存格式"}},[t._v("#")]),t._v(" 储存格式")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",{staticStyle:{"text-align":"left"}},[t._v("存储格式")]),t._v(" "),s("th",{staticStyle:{"text-align":"left"}},[t._v("存储方式")]),t._v(" "),s("th",{staticStyle:{"text-align":"left"}},[t._v("特点")])])]),t._v(" "),s("tbody",[s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("TextFile")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("行存储")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("存储空间消耗比较大，并且压缩的text 无法分割和合并 查询的效率最低,可以直接存储，加载数据的速度最高")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("SequenceFile")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("行存储")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("存储空间消耗最大,压缩的文件可以分割和合并 查询效率高，需要通过text文件转化来加载")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("RCFile")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("数据按行分块 每块按照列存储")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("存储空间最小，查询的效率最高 ，需要通过text文件转化来加载，加载的速度最低。压缩快 快速列存取。读记录尽量涉及到的block最少 读取需要的列只需要读取每个row group 的头部定义。 读取全量数据的操作 性能可能比sequencefile没有明显的优势")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("ORCFile")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("数据按行分块 每块按照列存储")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("压缩快,快速列存取 ,效率比rcfile高,是rcfile的改良版本")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"left"}},[t._v("Parquet")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("列存储")]),t._v(" "),s("td",{staticStyle:{"text-align":"left"}},[t._v("相对于PRC，Parquet压缩比较低，查询效率较低，不支持update、insert和ACID.但是Parquet支持Impala查询引擎")])])])]),t._v(" "),s("p",[t._v("https://blog.csdn.net/u010003835/article/details/81098325")]),t._v(" "),s("p",[t._v("压缩和解压缩会增加额外的CPU开销，Hadoop的job通常是I/O密集型而不是CPU密集型的，通过减少载入内存的数据量而提高I/O吞吐量会更加提高网络传输性能。")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",[t._v("压缩格式")]),t._v(" "),s("th",[t._v("是否可拆分")]),t._v(" "),s("th",[t._v("是否自带")]),t._v(" "),s("th",[t._v("压缩率")]),t._v(" "),s("th",[t._v("速度")]),t._v(" "),s("th",[t._v("是否hadoop自带")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("gzip")]),t._v(" "),s("td",[t._v("否")]),t._v(" "),s("td",[t._v("是")]),t._v(" "),s("td",[t._v("很高")]),t._v(" "),s("td",[t._v("比较快")]),t._v(" "),s("td",[t._v("是")])]),t._v(" "),s("tr",[s("td",[t._v("lzo")]),t._v(" "),s("td",[t._v("是")]),t._v(" "),s("td",[t._v("是")]),t._v(" "),s("td",[t._v("比较高")]),t._v(" "),s("td",[t._v("很快")]),t._v(" "),s("td",[t._v("否，要安装")])]),t._v(" "),s("tr",[s("td",[t._v("snappy")]),t._v(" "),s("td",[t._v("否")]),t._v(" "),s("td",[t._v("是")]),t._v(" "),s("td",[t._v("比较高")]),t._v(" "),s("td",[t._v("很快")]),t._v(" "),s("td",[t._v("否，要安装")])]),t._v(" "),s("tr",[s("td",[t._v("bzip2")]),t._v(" "),s("td",[t._v("是")]),t._v(" "),s("td",[t._v("否")]),t._v(" "),s("td",[t._v("最高")]),t._v(" "),s("td",[t._v("慢")]),t._v(" "),s("td",[t._v("是")])])])]),t._v(" "),s("h5",{attrs:{id:"字段格式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#字段格式"}},[t._v("#")]),t._v(" 字段格式")]),t._v(" "),s("p",[t._v("而是要考虑一定的数据清洗，比如异常字段的处理、字段命名规范化、时间字段的统一等，一般这些很容易会被忽略，但是却至关重要")]),t._v(" "),s("h4",{attrs:{id:"hivesql"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hivesql"}},[t._v("#")]),t._v(" HiveSQL")]),t._v(" "),s("h5",{attrs:{id:"列裁剪和分区裁剪"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#列裁剪和分区裁剪"}},[t._v("#")]),t._v(" 列裁剪和分区裁剪")]),t._v(" "),s("p",[t._v("最基本的操作。所谓列裁剪就是在查询时只读取需要的列，分区裁剪就是只读取需要的分区")]),t._v(" "),s("h5",{attrs:{id:"避免全表扫描"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#避免全表扫描"}},[t._v("#")]),t._v(" 避免全表扫描")]),t._v(" "),s("p",[t._v("对分区列动态的计算比较会引起全表扫描")]),t._v(" "),s("div",{staticClass:"language-sql line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("usernum"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" usernum\n          "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" tb_test\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" cp "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020040500")]),t._v("\n           "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v(" cp "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v("\n               from_unixtime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("unix_timestamp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2020040500'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'yyyyMMddHH'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("\n                             "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("24")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("60")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("60")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                             "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'yyyyMMddHH'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("group")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" usernum"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 或者")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("usernum"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" usernum\n          "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" tb_test\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" cp "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("in")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n           "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" cp "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" xxx\n         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n       "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("group")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" usernum"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n \n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br")])]),s("p",[t._v("尽量固定分区列范围")]),t._v(" "),s("div",{staticClass:"language-sql line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("usernum"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" usernum\n          "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" tb_test\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" cp "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020040500")]),t._v("\n           "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v(" cp "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2020033000")]),t._v("\n         "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("group")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" usernum"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br")])]),s("h5",{attrs:{id:"谓词下推"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#谓词下推"}},[t._v("#")]),t._v(" 谓词下推")]),t._v(" "),s("p",[t._v("将SQL语句中的where谓词逻辑都尽可能提前执行，减少下游处理的数据量。")]),t._v(" "),s("div",{staticClass:"language-sql line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("uid"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("event_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("topic_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("title\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" calendar_record_log a\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("left")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("outer")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("join")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" uid"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("topic_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("title "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" forum_topic\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" pt_date "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20190224")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v(" length"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("content"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" b "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("on")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("uid "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("uid\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pt_date "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20190224")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("status")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br")])]),s("p",[t._v("对forum_topic做过滤的where语句写在子查询内部，而不是外部。Hive中有谓词下推优化的配置项"),s("code",[t._v("hive.optimize.ppd")]),t._v("，默认值true，与它对应的逻辑优化器是PredicatePushDown。该优化器就是将OperatorTree中的FilterOperator向上提")]),t._v(" "),s("p",[t._v("讲解HiveSQL解析与执行过程:")]),t._v(" "),s("p",[t._v("https://tech.meituan.com/2014/02/12/hive-sql-to-mapreduce.html")]),t._v(" "),s("h5",{attrs:{id:"sort-by代替order-by"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sort-by代替order-by"}},[t._v("#")]),t._v(" sort by代替order by")]),t._v(" "),s("p",[t._v("HiveSQL中的order by与其他SQL方言中的功能一样，就是将结果按某字段全局排序，这会导致所有map端数据都进入一个reducer中，在数据量大时可能会长时间计算不完。")]),t._v(" "),s("p",[t._v("如果使用sort by，那么还是会视情况启动多个reducer进行排序，并且保证每个reducer内局部有序。为了控制map端数据分配到reducer的key，往往还要配合distribute by一同使用。如果不加distribute by的话，map端数据就会随机分配到reducer。 举个例子，假如要以UID为key，以上传时间倒序、记录类型倒序输出记录数据：")]),t._v(" "),s("div",{staticClass:"language-sql line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" uid"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("upload_time"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("event_type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("record_data\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" calendar_record_log\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" pt_date "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20190201")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v(" pt_date "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20190224")]),t._v("\ndistribute "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" uid\nsort "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" upload_time "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("desc")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("event_type "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("desc")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br")])]),s("h5",{attrs:{id:"group-by代替distinct"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#group-by代替distinct"}},[t._v("#")]),t._v(" group by代替distinct")]),t._v(" "),s("p",[t._v("当要统计某一列的去重数时，如果数据量很大，count(distinct)就会非常慢，原因与order by类似，count(distinct)逻辑只会有很少的reducer来处理。这时可以用group by来改写：")]),t._v(" "),s("div",{staticClass:"language-sql line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" uid "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" calendar_record_log\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" pt_date "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("20190101")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("group")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" uid\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br")])]),s("p",[t._v("但是这样写会启动两个MR job（单纯distinct只会启动一个），所以要确保数据量大到启动job的overhead远小于计算耗时，才考虑这种方法。当数据集很小或者key的倾斜比较明显时，group by还可能会比distinct慢。 那么如何用group by方式同时统计多个列？下面是解决方法：")]),t._v(" "),s("div",{staticClass:"language-sql line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("null")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("null")]),t._v(" d "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" some_table\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("union")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("all")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("null")]),t._v(" d "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" some_table "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("group")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("c\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("union")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("all")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("null")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("d "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" some_table "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("group")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("d\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br")])]),s("h5",{attrs:{id:"join将大表放后头-最新版本的hive会优化"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#join将大表放后头-最新版本的hive会优化"}},[t._v("#")]),t._v(" Join将大表放后头(最新版本的hive会优化)")]),t._v(" "),s("p",[t._v("Hive假定查询中最后的一个表是大表。它会将其它表缓存起来，然后扫描最后那个表。因此通常需要将小表放前面，或者标记哪张表是大表：/*streamtable(table_name) */")]),t._v(" "),s("h5",{attrs:{id:"使用相同的连接键"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#使用相同的连接键"}},[t._v("#")]),t._v(" 使用相同的连接键")]),t._v(" "),s("p",[t._v("当对3个或者更多个表进行join连接时，如果每个on子句都使用相同的连接键的话，那么只会产生一个MapReduce job。")]),t._v(" "),s("h5",{attrs:{id:"尽量原子化操作"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#尽量原子化操作"}},[t._v("#")]),t._v(" 尽量原子化操作")]),t._v(" "),s("p",[t._v("尽量避免一个SQL包含复杂逻辑，可以使用中间表来完成复杂的逻辑")]),t._v(" "),s("h4",{attrs:{id:"参数调优"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#参数调优"}},[t._v("#")]),t._v(" 参数调优")]),t._v(" "),s("h5",{attrs:{id:"mapreduce优化"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce优化"}},[t._v("#")]),t._v(" MapReduce优化")]),t._v(" "),s("h5",{attrs:{id:"调整mapper数"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#调整mapper数"}},[t._v("#")]),t._v(" "),s("strong",[t._v("调整mapper数")])]),t._v(" "),s("p",[t._v("mapper数量与输入文件的split数息息相关，在Hadoop源码"),s("code",[t._v("org.apache.hadoop.mapreduce.lib.input.FileInputFormat")]),t._v("类中可以看到split划分的具体逻辑。这里不贴代码，直接叙述mapper数是如何确定的。")]),t._v(" "),s("ul",[s("li",[t._v("可以直接通过参数"),s("code",[t._v("mapred.map.tasks")]),t._v("（默认值2）来设定mapper数的期望值，但它不一定会生效，下面会提到。")]),t._v(" "),s("li",[t._v("设输入文件的总大小为"),s("code",[t._v("total_input_size")]),t._v("。HDFS中，一个块的大小由参数"),s("code",[t._v("dfs.block.size")]),t._v("指定，默认值64MB或128MB。在默认情况下，mapper数就是： "),s("code",[t._v("default_mapper_num = total_input_size / dfs.block.size")]),t._v("。")]),t._v(" "),s("li",[t._v("参数"),s("code",[t._v("mapred.min.split.size")]),t._v("（默认值1B）和"),s("code",[t._v("mapred.max.split.size")]),t._v("（默认值64MB）分别用来指定split的最小和最大大小。split大小和split数计算规则是： "),s("code",[t._v("split_size = MAX(mapred.min.split.size, MIN(mapred.max.split.size, dfs.block.size))")]),t._v("； "),s("code",[t._v("split_num = total_input_size / split_size")]),t._v("。")]),t._v(" "),s("li",[t._v("得出mapper数： "),s("code",[t._v("mapper_num = MIN(split_num, MAX(default_num, mapred.map.tasks))")]),t._v("。")])]),t._v(" "),s("p",[t._v("可见，如果想减少mapper数，就适当调高"),s("code",[t._v("mapred.min.split.size")]),t._v("，split数就减少了。如果想增大mapper数，除了降低"),s("code",[t._v("mapred.min.split.size")]),t._v("之外，也可以调高"),s("code",[t._v("mapred.map.tasks")]),t._v("。")]),t._v(" "),s("p",[t._v("一般来讲，如果输入文件是少量大文件，就减少mapper数；如果输入文件是大量非小文件，就增大mapper数；至于大量小文件的情况，得参考下面“合并小文件”一节的方法处理。")]),t._v(" "),s("h5",{attrs:{id:"调整reducer数"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#调整reducer数"}},[t._v("#")]),t._v(" "),s("strong",[t._v("调整reducer数")])]),t._v(" "),s("p",[t._v("reducer数量的确定方法比mapper简单得多。使用参数"),s("code",[t._v("mapred.reduce.tasks")]),t._v("可以直接设定reducer数量，不像mapper一样是期望值。但如果不设这个参数的话，Hive就会自行推测，逻辑如下：")]),t._v(" "),s("ul",[s("li",[t._v("参数"),s("code",[t._v("hive.exec.reducers.bytes.per.reducer")]),t._v("用来设定每个reducer能够处理的最大数据量，默认值1G（1.2版本之前）或256M（1.2版本之后）。")]),t._v(" "),s("li",[t._v("参数"),s("code",[t._v("hive.exec.reducers.max")]),t._v("用来设定每个job的最大reducer数量，默认值999（1.2版本之前）或1009（1.2版本之后）。")]),t._v(" "),s("li",[t._v("得出reducer数： "),s("code",[t._v("reducer_num = MIN(total_input_size / reducers.bytes.per.reducer, reducers.max)")]),t._v("。")])]),t._v(" "),s("p",[t._v("reducer数量与输出文件的数量相关。如果reducer数太多，会产生大量小文件，对HDFS造成压力。如果reducer数太少，每个reducer要处理很多数据，容易拖慢运行时间或者造成OOM。")]),t._v(" "),s("h5",{attrs:{id:"合并小文件"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#合并小文件"}},[t._v("#")]),t._v(" "),s("strong",[t._v("合并小文件")])]),t._v(" "),s("ul",[s("li",[t._v("输入阶段合并 需要更改Hive的输入文件格式，即参数"),s("code",[t._v("hive.input.format")]),t._v("，默认值是"),s("code",[t._v("org.apache.hadoop.hive.ql.io.HiveInputFormat")]),t._v("，我们改成"),s("code",[t._v("org.apache.hadoop.hive.ql.io.CombineHiveInputFormat")]),t._v("。 这样比起上面调整mapper数时，又会多出两个参数，分别是"),s("code",[t._v("mapred.min.split.size.per.node")]),t._v("和"),s("code",[t._v("mapred.min.split.size.per.rack")]),t._v("，含义是单节点和单机架上的最小split大小。如果发现有split大小小于这两个值（默认都是100MB），则会进行合并。具体逻辑可以参看Hive源码中的对应类。")]),t._v(" "),s("li",[t._v("输出阶段合并 直接将"),s("code",[t._v("hive.merge.mapfiles")]),t._v("和"),s("code",[t._v("hive.merge.mapredfiles")]),t._v("都设为true即可，前者表示将map-only任务的输出合并，后者表示将map-reduce任务的输出合并。 另外，"),s("code",[t._v("hive.merge.size.per.task")]),t._v("可以指定每个task输出后合并文件大小的期望值，"),s("code",[t._v("hive.merge.size.smallfiles.avgsize")]),t._v("可以指定所有输出文件大小的均值阈值，默认值都是1GB。如果平均大小不足的话，就会另外启动一个任务来进行合并。")])]),t._v(" "),s("h5",{attrs:{id:"启用压缩"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#启用压缩"}},[t._v("#")]),t._v(" "),s("strong",[t._v("启用压缩")])]),t._v(" "),s("p",[t._v("压缩job的中间结果数据和输出数据，可以用少量CPU时间节省很多空间。压缩方式一般选择Snappy，效率最高。 要启用中间压缩，需要设定"),s("code",[t._v("hive.exec.compress.intermediate")]),t._v("为true，同时指定压缩方式"),s("code",[t._v("hive.intermediate.compression.codec")]),t._v("为"),s("code",[t._v("org.apache.hadoop.io.compress.SnappyCodec")]),t._v("。另外，参数"),s("code",[t._v("hive.intermediate.compression.type")]),t._v("可以选择对块（BLOCK）还是记录（RECORD）压缩，BLOCK的压缩率比较高。 输出压缩的配置基本相同，打开"),s("code",[t._v("hive.exec.compress.output")]),t._v("即可。")]),t._v(" "),s("h5",{attrs:{id:"jvm重用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#jvm重用"}},[t._v("#")]),t._v(" "),s("strong",[t._v("JVM重用")])]),t._v(" "),s("p",[t._v("在MR job中，默认是每执行一个task就启动一个JVM。如果task非常小而碎，那么JVM启动和关闭的耗时就会很长。可以通过调节参数"),s("code",[t._v("mapred.job.reuse.jvm.num.tasks")]),t._v("来重用。例如将这个参数设成5，那么就代表同一个MR job中顺序执行的5个task可以重复使用一个JVM，减少启动和关闭的开销。但它对不同MR job中的task无效。")]),t._v(" "),s("h5",{attrs:{id:"并行执行与本地模式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#并行执行与本地模式"}},[t._v("#")]),t._v(" 并行执行与本地模式")]),t._v(" "),s("ul",[s("li",[t._v("并行执行 Hive中互相没有依赖关系的job间是可以并行执行的，最典型的就是多个子查询union all。在集群资源相对充足的情况下，可以开启并行执行，即将参数"),s("code",[t._v("hive.exec.parallel")]),t._v("设为true。另外"),s("code",[t._v("hive.exec.parallel.thread.number")]),t._v("可以设定并行执行的线程数，默认为8，一般都够用。")]),t._v(" "),s("li",[t._v("本地模式 Hive也可以不将任务提交到集群进行运算，而是直接在一台节点上处理。因为消除了提交到集群的overhead，所以比较适合数据量很小，且逻辑不复杂的任务。 设置"),s("code",[t._v("hive.exec.mode.local.auto")]),t._v("为true可以开启本地模式。但任务的输入数据总量必须小于"),s("code",[t._v("hive.exec.mode.local.auto.inputbytes.max")]),t._v("（默认值128MB），且mapper数必须小于"),s("code",[t._v("hive.exec.mode.local.auto.tasks.max")]),t._v("（默认值4），reducer数必须为0或1，才会真正用本地模式执行。")])]),t._v(" "),s("h5",{attrs:{id:"严格模式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#严格模式"}},[t._v("#")]),t._v(" 严格模式")]),t._v(" "),s("p",[t._v("所谓严格模式，就是强制不允许用户执行3种有风险的HiveSQL语句，一旦执行会直接失败。这3种语句是：")]),t._v(" "),s("ul",[s("li",[t._v("查询分区表时不限定分区列的语句；")]),t._v(" "),s("li",[t._v("两表join产生了笛卡尔积的语句；")]),t._v(" "),s("li",[t._v("用order by来排序但没有指定limit的语句。")])]),t._v(" "),s("p",[t._v("要开启严格模式，需要将参数"),s("code",[t._v("hive.mapred.mode")]),t._v("设为strict。")]),t._v(" "),s("h4",{attrs:{id:"探索"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#探索"}},[t._v("#")]),t._v(" 探索")]),t._v(" "),s("h5",{attrs:{id:"full-join"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#full-join"}},[t._v("#")]),t._v(" FULL JOIN")]),t._v(" "),s("div",{staticClass:"language-sql line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DROP")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DROP")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("DROP")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("table")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("IF")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("EXISTS")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\nuser_id "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\na string\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("IF")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("EXISTS")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\nuser_id "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\nb string\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("IF")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("NOT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("EXISTS")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("c "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\nuser_id "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INT")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\nc string\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("user_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VALUES")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'1'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("user_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VALUES")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("user_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VALUES")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a的null'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("user_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VALUES")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'1'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("user_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VALUES")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'3'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("user_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VALUES")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'4'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("user_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VALUES")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'b的null'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("c "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("user_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VALUES")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'1'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("c "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("user_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VALUES")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'3'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INSERT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("INTO")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("c "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("user_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("VALUES")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("NULL")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'c的null'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("WITH")]),t._v(" user_group "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("AS")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" user_id "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" user_id "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("GROUP")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" user_id \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("UNION")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ALL")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" user_id "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("GROUP")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" user_id \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("UNION")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ALL")]),t._v(" \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" user_id "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("c "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("GROUP")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" user_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" t "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("GROUP")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("BY")]),t._v(" t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("user_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" u"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("user_id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("c "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" user_group "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" u \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("LEFT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("a "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" a \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" u"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("user_id "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("user_id \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("LEFT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("b "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" b \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" u"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("user_id "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("user_id \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("LEFT")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("JOIN")]),t._v(" test"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("c "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" c \n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("ON")]),t._v(" u"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("user_id "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("user_id \n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 多表FULL JOIN一定要注意，会出现没有join上的情况")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- SELECT a.user_id, b.user_id, c.user_id, a.a, b.b, c.c FROM ")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- (SELECT * FROM test.a where user_id is NOT NULL) as a")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- FULL JOIN (SELECT * FROM test.b where user_id is NOT NULL) as b")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- ON a.user_id = b.user_id")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- FULL JOIN (SELECT * FROM test.c where user_id is NOT NULL) as c")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- ON a.user_id = c.user_id and b.user_id = c.user_id")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br"),s("span",{staticClass:"line-number"},[t._v("12")]),s("br"),s("span",{staticClass:"line-number"},[t._v("13")]),s("br"),s("span",{staticClass:"line-number"},[t._v("14")]),s("br"),s("span",{staticClass:"line-number"},[t._v("15")]),s("br"),s("span",{staticClass:"line-number"},[t._v("16")]),s("br"),s("span",{staticClass:"line-number"},[t._v("17")]),s("br"),s("span",{staticClass:"line-number"},[t._v("18")]),s("br"),s("span",{staticClass:"line-number"},[t._v("19")]),s("br"),s("span",{staticClass:"line-number"},[t._v("20")]),s("br"),s("span",{staticClass:"line-number"},[t._v("21")]),s("br"),s("span",{staticClass:"line-number"},[t._v("22")]),s("br"),s("span",{staticClass:"line-number"},[t._v("23")]),s("br"),s("span",{staticClass:"line-number"},[t._v("24")]),s("br"),s("span",{staticClass:"line-number"},[t._v("25")]),s("br"),s("span",{staticClass:"line-number"},[t._v("26")]),s("br"),s("span",{staticClass:"line-number"},[t._v("27")]),s("br"),s("span",{staticClass:"line-number"},[t._v("28")]),s("br"),s("span",{staticClass:"line-number"},[t._v("29")]),s("br"),s("span",{staticClass:"line-number"},[t._v("30")]),s("br"),s("span",{staticClass:"line-number"},[t._v("31")]),s("br"),s("span",{staticClass:"line-number"},[t._v("32")]),s("br"),s("span",{staticClass:"line-number"},[t._v("33")]),s("br"),s("span",{staticClass:"line-number"},[t._v("34")]),s("br"),s("span",{staticClass:"line-number"},[t._v("35")]),s("br"),s("span",{staticClass:"line-number"},[t._v("36")]),s("br"),s("span",{staticClass:"line-number"},[t._v("37")]),s("br"),s("span",{staticClass:"line-number"},[t._v("38")]),s("br"),s("span",{staticClass:"line-number"},[t._v("39")]),s("br"),s("span",{staticClass:"line-number"},[t._v("40")]),s("br"),s("span",{staticClass:"line-number"},[t._v("41")]),s("br"),s("span",{staticClass:"line-number"},[t._v("42")]),s("br"),s("span",{staticClass:"line-number"},[t._v("43")]),s("br"),s("span",{staticClass:"line-number"},[t._v("44")]),s("br"),s("span",{staticClass:"line-number"},[t._v("45")]),s("br"),s("span",{staticClass:"line-number"},[t._v("46")]),s("br"),s("span",{staticClass:"line-number"},[t._v("47")]),s("br"),s("span",{staticClass:"line-number"},[t._v("48")]),s("br"),s("span",{staticClass:"line-number"},[t._v("49")]),s("br"),s("span",{staticClass:"line-number"},[t._v("50")]),s("br"),s("span",{staticClass:"line-number"},[t._v("51")]),s("br")])])])}),[],!1,null,null,null);s.default=n.exports}}]);